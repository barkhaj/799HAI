{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPYLmAm2y374"
   },
   "source": [
    "#### [My GitHub link](https://github.com/barkhaj/799HAIWK1)!\n",
    "\n",
    "Welcome to your assignment this week! \n",
    "\n",
    "\n",
    "# Classification task\n",
    "In this task you are asked to build a simple Feed Forward Neural Network, train it and test it!\n",
    "\n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Load a dataset.\n",
    "- Train a Feed Forward Neural Network.\n",
    "- Test a Feed Forward Neural Network.\n",
    "\n",
    "Let's get started! Run the following cell to install all the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MwVJpPoAy374"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install nbconvert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x67z_R3_y375"
   },
   "source": [
    "Run the following cell to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0K67BsATy375"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#performance evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiJC_sYzy375"
   },
   "source": [
    "The dataset we will use consists of 4500 examples with 512 features. A label is given for each example to indicate positive and negative instances.\n",
    "\n",
    "Let's read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ltzm-RMuy376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 513)\n",
      "         v1       v2       v3       v4       v5       v6       v7       v8  \\\n",
      "id                                                                           \n",
      "1   0.37797 -0.94808  0.01346  0.17893  0.37795  0.63571  0.13943 -0.25607   \n",
      "2   0.07609 -0.09774  0.39666 -0.39026  0.10606  0.52774  0.07105  0.33720   \n",
      "3   1.19391 -0.68707 -0.68422 -0.36378 -0.60847 -0.40118  1.45432  0.00592   \n",
      "4   1.34949 -0.31498 -1.30248  0.50278  1.66292 -1.06094 -0.70835 -0.24237   \n",
      "5  -0.03512 -0.34196  0.14230  1.50513 -0.14364  0.49429  0.07823 -0.04356   \n",
      "\n",
      "         v9      v10  ...     v504     v505     v506     v507     v508  \\\n",
      "id                    ...                                                \n",
      "1  -0.39341  1.08947  ... -0.03494  1.32443 -0.94570  0.02055 -1.23908   \n",
      "2   0.69917 -0.02842  ...  0.86624 -1.24953 -0.21511 -1.54146  1.04765   \n",
      "3   1.68940 -0.98205  ... -0.35893  0.02330  0.31548 -0.34923 -0.41772   \n",
      "4  -0.15509 -0.04532  ...  0.23942  0.20774  0.81792 -0.74814 -0.62521   \n",
      "5   0.42009 -0.88828  ... -1.78407  0.07465  1.50182 -0.41289 -0.55908   \n",
      "\n",
      "       v509     v510     v511     v512  label  \n",
      "id                                             \n",
      "1   0.43507  1.08635  1.69027  0.61609      0  \n",
      "2  -1.24035  0.00866 -1.27640 -0.60496      1  \n",
      "3  -0.58175 -0.60177  0.43555  0.41982      1  \n",
      "4   0.01689  0.83997 -0.46986  0.06755      0  \n",
      "5  -0.29702  0.83641  0.59756 -0.20298      0  \n",
      "\n",
      "[5 rows x 513 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.set_index('id', inplace=True)\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnCcO3a6y377"
   },
   "source": [
    "Now, let's split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7WUzliVZy377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \n",
      " (4500, 514)\n",
      "         v1       v2       v3       v4       v5       v6       v7       v8  \\\n",
      "id                                                                           \n",
      "1   0.37797 -0.94808  0.01346  0.17893  0.37795  0.63571  0.13943 -0.25607   \n",
      "2   0.07609 -0.09774  0.39666 -0.39026  0.10606  0.52774  0.07105  0.33720   \n",
      "3   1.19391 -0.68707 -0.68422 -0.36378 -0.60847 -0.40118  1.45432  0.00592   \n",
      "4   1.34949 -0.31498 -1.30248  0.50278  1.66292 -1.06094 -0.70835 -0.24237   \n",
      "5  -0.03512 -0.34196  0.14230  1.50513 -0.14364  0.49429  0.07823 -0.04356   \n",
      "\n",
      "         v9      v10  ...     v505     v506     v507     v508     v509  \\\n",
      "id                    ...                                                \n",
      "1  -0.39341  1.08947  ...  1.32443 -0.94570  0.02055 -1.23908  0.43507   \n",
      "2   0.69917 -0.02842  ... -1.24953 -0.21511 -1.54146  1.04765 -1.24035   \n",
      "3   1.68940 -0.98205  ...  0.02330  0.31548 -0.34923 -0.41772 -0.58175   \n",
      "4  -0.15509 -0.04532  ...  0.20774  0.81792 -0.74814 -0.62521  0.01689   \n",
      "5   0.42009 -0.88828  ...  0.07465  1.50182 -0.41289 -0.55908 -0.29702   \n",
      "\n",
      "       v510     v511     v512  label  data_type  \n",
      "id                                               \n",
      "1   1.08635  1.69027  0.61609      0      train  \n",
      "2   0.00866 -1.27640 -0.60496      1      train  \n",
      "3  -0.60177  0.43555  0.41982      1      train  \n",
      "4   0.83997 -0.46986  0.06755      0       test  \n",
      "5   0.83641  0.59756 -0.20298      0      train  \n",
      "\n",
      "[5 rows x 514 columns]\n",
      "X_train\n",
      " (3825, 512)\n",
      "X_test \n",
      " (675, 512)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")\n",
    "df['data_type'] = ['note_set']*df.shape[0]\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_test, 'data_type'] = 'test'\n",
    "\n",
    "#Examine dataset\n",
    "print(\"Dataset \\n\",df.shape)\n",
    "print(df.head(5))\n",
    "\n",
    "\n",
    "## The data to use:\n",
    "X_train = df[df['data_type']=='train'].iloc[:,:512].values\n",
    "X_test = df[df['data_type']=='test'].iloc[:,:512].values\n",
    "y_train = df[df['data_type']=='train'].iloc[:,512:513].values\n",
    "y_test = df[df['data_type']=='test'].iloc[:,512:513].values\n",
    "\n",
    "\n",
    "#Examine training and test data\n",
    "print(\"X_train\\n\",X_train.shape)\n",
    "print(\"X_test \\n\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ga4DGNTy377"
   },
   "source": [
    "# Task 1\n",
    "\n",
    "Build a Feed Forward Neural Network to address this classification task using the Keras framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i8d-psy2y378"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "  Dense(12, activation='relu', input_shape=(512,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwfUGs9Ty378"
   },
   "source": [
    "# Training\n",
    "\n",
    "Now, let's start our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fn7fPEvTy378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - 1s 2ms/step - loss: 0.6232 - accuracy: 0.6268\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8785\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.0824 - accuracy: 0.9867\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.0261 - accuracy: 0.9963\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.0099 - accuracy: 0.9992\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 0.0055 - accuracy: 0.9999\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "60/60 [==============================] - 0s 617us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "60/60 [==============================] - 0s 606us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "60/60 [==============================] - 0s 628us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 7.0545e-04 - accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 6.6492e-04 - accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 5.0062e-04 - accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "60/60 [==============================] - 0s 641us/step - loss: 4.2113e-04 - accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "60/60 [==============================] - 0s 611us/step - loss: 3.8081e-04 - accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "60/60 [==============================] - 0s 648us/step - loss: 3.1600e-04 - accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "60/60 [==============================] - 0s 628us/step - loss: 2.6348e-04 - accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.4897e-04 - accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.1370e-04 - accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "60/60 [==============================] - 0s 610us/step - loss: 1.6019e-04 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.6400e-04 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 1.4051e-04 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.2437e-04 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "60/60 [==============================] - 0s 608us/step - loss: 1.1625e-04 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "60/60 [==============================] - 0s 610us/step - loss: 1.0978e-04 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.0149e-04 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "60/60 [==============================] - 0s 608us/step - loss: 9.0923e-05 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 8.4390e-05 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "60/60 [==============================] - 0s 641us/step - loss: 7.7339e-05 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 7.3212e-05 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 6.4416e-05 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 5.7163e-05 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 5.3253e-05 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 4.8936e-05 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "60/60 [==============================] - 0s 630us/step - loss: 4.6912e-05 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 4.4161e-05 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "60/60 [==============================] - 0s 647us/step - loss: 4.0206e-05 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 3.8976e-05 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 3.7309e-05 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 3.4348e-05 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 3.0388e-05 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 3.1126e-05 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 2.5001e-05 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.4625e-05 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.4075e-05 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 2.3338e-05 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.0668e-05 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 2.0876e-05 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 2.1216e-05 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "60/60 [==============================] - 0s 632us/step - loss: 1.9865e-05 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "60/60 [==============================] - 0s 645us/step - loss: 1.6788e-05 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.7890e-05 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 1.5590e-05 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 1.5411e-05 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.4703e-05 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 1.3878e-05 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 1.2375e-05 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.2883e-05 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.2172e-05 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "60/60 [==============================] - 0s 633us/step - loss: 1.0848e-05 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 9.7905e-06 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 9.6422e-06 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "60/60 [==============================] - 0s 643us/step - loss: 9.1601e-06 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 8.6935e-06 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 8.5016e-06 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 8.0811e-06 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 7.5345e-06 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 7.3946e-06 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 7.2909e-06 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 7.0890e-06 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 6.8228e-06 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "60/60 [==============================] - 0s 624us/step - loss: 5.9209e-06 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 6.4409e-06 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 5.6566e-06 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 5.3850e-06 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 5.6520e-06 - accuracy: 1.0000\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 629us/step - loss: 4.8617e-06 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 4.6248e-06 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 4.6597e-06 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "60/60 [==============================] - 0s 629us/step - loss: 4.6175e-06 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 3.9866e-06 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 4.4298e-06 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 4.0796e-06 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 3.7088e-06 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 3.7729e-06 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 3.5332e-06 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 3.6059e-06 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 3.5246e-06 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "60/60 [==============================] - 0s 629us/step - loss: 3.0681e-06 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 2.9536e-06 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.6585e-06 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 2.6723e-06 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 2.4947e-06 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 2.4205e-06 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.4822e-06 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 2.6105e-06 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 2.1846e-06 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "60/60 [==============================] - 0s 626us/step - loss: 2.1766e-06 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 2.0686e-06 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "60/60 [==============================] - 0s 643us/step - loss: 1.9592e-06 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 2.0218e-06 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.9104e-06 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.7623e-06 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.6203e-06 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.6606e-06 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.5311e-06 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.4919e-06 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.5756e-06 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.4579e-06 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 1.3156e-06 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 1.3131e-06 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 1.3375e-06 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.3842e-06 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "60/60 [==============================] - 0s 643us/step - loss: 1.1680e-06 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 1.0759e-06 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "60/60 [==============================] - 0s 654us/step - loss: 1.0292e-06 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "60/60 [==============================] - 0s 641us/step - loss: 1.1421e-06 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 9.9986e-07 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 8.8412e-07 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 9.8455e-07 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 9.5233e-07 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "60/60 [==============================] - 0s 639us/step - loss: 8.0379e-07 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 8.6673e-07 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "60/60 [==============================] - 0s 645us/step - loss: 7.3041e-07 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "60/60 [==============================] - 0s 645us/step - loss: 7.9562e-07 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "60/60 [==============================] - 0s 616us/step - loss: 6.6847e-07 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "60/60 [==============================] - 0s 643us/step - loss: 6.9003e-07 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 6.7099e-07 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "60/60 [==============================] - 0s 609us/step - loss: 6.5076e-07 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 6.4913e-07 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "60/60 [==============================] - 0s 636us/step - loss: 6.1292e-07 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 5.9264e-07 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 5.8822e-07 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "60/60 [==============================] - 0s 625us/step - loss: 4.8951e-07 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "60/60 [==============================] - 0s 663us/step - loss: 5.2198e-07 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 5.0092e-07 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "60/60 [==============================] - 0s 643us/step - loss: 4.4851e-07 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 5.1813e-07 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "60/60 [==============================] - 0s 710us/step - loss: 4.6383e-07 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "60/60 [==============================] - 0s 712us/step - loss: 4.3429e-07 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 4.3989e-07 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 4.3145e-07 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "60/60 [==============================] - 0s 645us/step - loss: 3.9592e-07 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "60/60 [==============================] - 0s 695us/step - loss: 3.7998e-07 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 3.5211e-07 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 4.0418e-07 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "60/60 [==============================] - 0s 633us/step - loss: 3.3343e-07 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 3.2518e-07 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 3.2858e-07 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 2.6962e-07 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 3.0953e-07 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "60/60 [==============================] - 0s 645us/step - loss: 2.8293e-07 - accuracy: 1.0000\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 659us/step - loss: 2.8456e-07 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 2.7389e-07 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 2.4648e-07 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "60/60 [==============================] - 0s 693us/step - loss: 2.5299e-07 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4331e-07 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "60/60 [==============================] - 0s 705us/step - loss: 2.4195e-07 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "60/60 [==============================] - 0s 727us/step - loss: 2.4471e-07 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 2.0848e-07 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "60/60 [==============================] - 0s 662us/step - loss: 2.1603e-07 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 2.0766e-07 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "60/60 [==============================] - 0s 663us/step - loss: 2.0461e-07 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "60/60 [==============================] - 0s 661us/step - loss: 1.7668e-07 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 1.6750e-07 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "60/60 [==============================] - 0s 660us/step - loss: 1.7730e-07 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "60/60 [==============================] - 0s 643us/step - loss: 1.5920e-07 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 1.6066e-07 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 1.7020e-07 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "60/60 [==============================] - 0s 661us/step - loss: 1.5382e-07 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 1.4077e-07 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.5747e-07 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "60/60 [==============================] - 0s 654us/step - loss: 1.3655e-07 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.3915e-07 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "60/60 [==============================] - 0s 662us/step - loss: 1.3213e-07 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 1.2844e-07 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "60/60 [==============================] - 0s 644us/step - loss: 1.2323e-07 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 1.1524e-07 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 1.0749e-07 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 1.1374e-07 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "60/60 [==============================] - 0s 661us/step - loss: 1.0617e-07 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 1.0196e-07 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "60/60 [==============================] - 0s 661us/step - loss: 9.6783e-08 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "60/60 [==============================] - 0s 660us/step - loss: 9.8489e-08 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "60/60 [==============================] - 0s 627us/step - loss: 8.4797e-08 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "60/60 [==============================] - 0s 658us/step - loss: 8.8211e-08 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 8.6236e-08 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 8.0528e-08 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "60/60 [==============================] - 0s 661us/step - loss: 7.6199e-08 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 7.2479e-08 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 7.5208e-08 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 6.9545e-08 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 7.3950e-08 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 7.8086e-08 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "60/60 [==============================] - 0s 646us/step - loss: 6.7422e-08 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "60/60 [==============================] - 0s 658us/step - loss: 6.3025e-08 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "60/60 [==============================] - 0s 646us/step - loss: 5.8112e-08 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "60/60 [==============================] - 0s 659us/step - loss: 5.7299e-08 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "60/60 [==============================] - 0s 642us/step - loss: 5.8648e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IMYgz8nAy378"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewyOTi3Ay378"
   },
   "source": [
    "# Task 2\n",
    "\n",
    "Test the model on the test set and report Precision, Recall, F1-Score, and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "f7IzXUJBy379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.990741\n",
      "Recall: 1.000000\n",
      "F1 score: 0.995349\n",
      "Accuracy: 0.994074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "#print(y_pred)\n",
    "\n",
    "# reduce to 1d array\n",
    "y_pred = y_pred[:, 0]\n",
    "#print(y_pred)\n",
    "\n",
    "#Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "#Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export your notebook to a pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Task1_3C_Classification_using_FFNN_Submit.ipynb to pdf\n",
      "[NbConvertApp] Support files will be in Task1_3C_Classification_using_FFNN_Submit_files\\\n",
      "[NbConvertApp] Making directory .\\Task1_3C_Classification_using_FFNN_Submit_files\n",
      "[NbConvertApp] Making directory .\\Task1_3C_Classification_using_FFNN_Submit_files\n",
      "[NbConvertApp] Writing 58924 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | b had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 75305 bytes to Task1_3C_Classification_using_FFNN_Submit.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert Task1_3C_Classification_using_FFNN_Submit.ipynb --to pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6vau2ijy379"
   },
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've come to the end of this assignment, and you have built your first neural network. \n",
    "\n",
    "Congratulations on finishing this notebook! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Brownlee J (2019) ['How to Calculate Precision, Recall, F1, and More for Deep Learning Models'](https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models), Deep Learning, Machine Learning Mastery, post Mar 29, accessed 28 July 2021\n",
    "\n",
    "Brownlee J (2019) ['Your First Deep Learning Project in Python with Keras Step-By-Step'](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/), Deep Learning, Machine Learning Mastery, post Jul 24, accessed 27 July 2021\n",
    "\n",
    "Zhou V (2019), ['Keras for Beginners: Building Your First Neural Network'](https://victorzhou.com/blog/keras-neural-network-tutorial/), accessed 26 July 2021\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.3C - Classification using FFNN.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
